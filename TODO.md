# TODO
- Currently:
  - Prompt is made by joining small, static text blocks
- This leads to:
  - Prompting logic is inflexible
- So, we're gonna:
  - Make prompting logic into single huge ChatML text block
  - and load corresponding that per usage(ex: main chat, random message, charactor creation)
- To do this:
  - Checking how prompt is made in current code
  - and change it so that prompt is loaded by only one function
  - (we should check out to ensure that no code is getting prompt text without that function)
  - and make that function load prompt from that huge text block
    - via browser local storage or something, there is a function about loading/saving something into browser so check out existing code
  - and make sure API functions are compatible with new prompt structure
  - and finally, modify a modal to use all new prompt strucure
- Keep in mind:
  - There are some people who are using custom prompts, so migration logic may be required
  - And the huge blocks are all ChatML prompt, so we need to ensure that no ChatML syntax error is in the blocks on modal
  - Use git commands to revert or check what changes are made
  - Use `pnpm run build:fe` to check if front-end code is building correctly
  - If possible, use JSDoc(but not mandatory if it's too much work)
  - You can ask me if you need a new dependency to add, or lacking information, etc
  - Do not use huge changes at once, instead make small changes multiple times
  - You can read this file again if you forget what to do
  - Files are huge, so be careful